{
  "articles": [
    {
      "path": "blog.html",
      "title": "Blog",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-03-07T01:16:01-08:00"
    },
    {
      "path": "index.html",
      "title": "Katelyn Toigo",
      "author": [],
      "contents": "\n\n          \n          \n          Katelyn Toigo\n          \n          \n          Home\n          Resume\n          \n          \n          Projects\n           \n          ▾\n          \n          \n          Project 1\n          Project 2\n          Project 3\n          Project 4\n          \n          \n          Blog\n          ☰\n          \n          \n      \n        \n          \n            \n              \n            \n              Katelyn Toigo\n            \n            \n              \n                \n                    \n                      \n                        LinkedIn\n                      \n                    \n                  \n                                    \n                    \n                      \n                        GitHub\n                      \n                    \n                  \n                                    \n                    \n                      \n                        Email\n                      \n                    \n                  \n                                  \n            \n          \n        \n        \n        \n          \n            \n            Summary\n            My determination to protect and restore biodiversity began as I grew up on an Illinois State Land and Water Reserve and traveled to national parks, refuges, and wilderness areas. While visiting Glacier National Park in 2008, I witnessed Ken Burns and his crew filming his national park documentary. When I viewed the film the next year, I was determined to make it to every U.S. national park. In June of 2016, a small Cessna landed on the sand dunes of Kobuk Valley National Park and my goal was achieved.\n            Earning a B.S. in Zoology and a B.S. in Geography and Environmental Resources from Southern Illinois University Carbondale laid the foundation to approach problems from both the perspective of societal needs and from the perspective of wildlife’s needs. Internships with The Nature Conservancy, the National Forest Foundation, Cypress Creek National Wildlife Refuge, and the National Great Rivers Research and Education Center enhanced skills in public education/outreach, collaboration, meeting facilitation, stewardship, and field methods. I am currently pursuing a Master of Environmental Science and Management degree at the University of California Santa Barbara Bren School, specializing in Conservation Planning.\n            \n          \n        \n      \n    \n\n    \n      \n        \n          \n            \n              \n            \n              Katelyn Toigo\n            \n            \n              \n                \n                                    \n                    \n                      LinkedIn\n                    \n                  \n                                    \n                    \n                      GitHub\n                    \n                  \n                                    \n                    \n                      Email\n                    \n                  \n                                  \n              \n            \n            \n              \n              Summary\n              My determination to protect and restore biodiversity began as I grew up on an Illinois State Land and Water Reserve and traveled to national parks, refuges, and wilderness areas. While visiting Glacier National Park in 2008, I witnessed Ken Burns and his crew filming his national park documentary. When I viewed the film the next year, I was determined to make it to every U.S. national park. In June of 2016, a small Cessna landed on the sand dunes of Kobuk Valley National Park and my goal was achieved.\n              Earning a B.S. in Zoology and a B.S. in Geography and Environmental Resources from Southern Illinois University Carbondale laid the foundation to approach problems from both the perspective of societal needs and from the perspective of wildlife’s needs. Internships with The Nature Conservancy, the National Forest Foundation, Cypress Creek National Wildlife Refuge, and the National Great Rivers Research and Education Center enhanced skills in public education/outreach, collaboration, meeting facilitation, stewardship, and field methods. I am currently pursuing a Master of Environmental Science and Management degree at the University of California Santa Barbara Bren School, specializing in Conservation Planning.\n              \n            \n        \n      \n    \n\n    \n    \n    ",
      "last_modified": "2022-03-07T01:16:01-08:00"
    },
    {
      "path": "projects.html",
      "title": "Projects",
      "description": "Projects Completed\n",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\nKatelyn Toigo\n\n\nHome\nResume\n\n\nProjects\n \n▾\n\n\nProject 1\nProject 2\nProject 3\nProject 4\n\n\nBlog\n☰\n\n\n  \n    \n      \n        \n        \n        \n      \n      \n    \n    \n      \n  Home\n\n\n  Resume\n\n\n  \n    Projects\n     \n    \n  \n  \n      Project 1\n    \n    \n      Project 2\n    \n    \n      Project 3\n    \n    \n      Project 4\n    \n  \n\n  Blog\n\n      \n  \n\n\n\n\n\nCode \nShow All Code\nHide All Code\n\n\n\n\nProjects\n\n\n\n\n\n1. Principal Components Analysis to Analyze Food Nutrients\n\nOverview\nThis script uses principal components analysis to analyze nutrient information for raw fruits and vegetables from the USDA National Nutrient Database (FoodDataCentral). Principal components analysis is an ordination method allowing us to understand as much about our multivariate data as possible in a simplified number of dimensions. Here, I’ll use the nutrients data from the USDA to explore variable relationships and clustering. I will only use the measurements that are in grams (protein, fat, carbohydrates, sugar, fiber), and I will only look at restaurant foods, baked products, and beef products.\nData citation: United States Department of Agriculture. https://fdc.nal.usda.gov/index.html\n\n\nAttach required packages:\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n \nlibrary(tidyverse)\nlibrary(here)\nlibrary(ggfortify) # For PCA biplot\nlibrary(patchwork)\nlibrary(broom)\n\n\nRead in the data\nnutrients <- read_csv(here(\"data\", \"usda_nutrients.csv\"))\n\n\nFilter the data\n# Filter food groups for restaurant foods, baked products, and beef products.\nnutrients_filter <- nutrients %>% \n  filter(FoodGroup == c(\"Restaurant Foods\", \"Baked Products\", \"Beef Products\"))\n\n\nRun the PCA\nnutrients_pca <- nutrients_filter %>% \n  select(ends_with('_g')) %>% \n  scale() %>% # scale the selected variables and pass to the prcomp() function\n  prcomp()\n\n\nCreate a biplot using autoplot\nautoplot(nutrients_pca,\n        data = nutrients_filter,\n        loadings = TRUE,\n        colour = 'FoodGroup', # colour needs to be British spelling\n        loadings.label = TRUE,\n        loadings.colour = \"black\",\n        loadings.label.colour = \"black\",\n        loadings.label.vjust = -0.5) +\n  theme_classic()\n\nFigure 1. PCA biplot between PC1 and PC2 when looking at protein, fiber, carbohydrates, sugar, and fat of baked products, beef products, and restaurant foods.\n\n\nSummary\nAll three food groups seem to have distinct clusters.\nBeef products associate more strongly with protein than with the other nutrients.\nFiber, carbs, and sugars tend to be more similar to each other than to protein. They are positively correlated.\nProtein is about 180 degrees different than carbs and sugars. This means they have a correlation of -1.\nFiber and fat have a correlation of 0 since they are about 90 degrees.\nBaked products are more similar to restaurant food than beef products based on these variables.\nOf the three clusters, beef products and baked products are the most different.\n\n\n\n2. Analysis of Seawater\n\nOverview\nThis analysis will look at the relationship between oxygen saturation of seawater off California’s coast and several physical and chemical variables including oxygen saturation, water temperature, water salinity, water depth, phosphate concentration, and nitrite concentrations.\nData citation: CalCOFI data are available for use without restriction. Data downloaded from https://calcofi.org/ccdata.html. Accessed 1/10/2022.\n\n\nAttach required packages\n# load packages\nlibrary(tidyverse)\nlibrary(here)\nlibrary(AICcmodavg)\nlibrary(equatiomatic)\n\n\nRead in the data\nseawater_samples <- read_csv(here('data', 'calcofi_seawater_samples.csv'))\n\n\nClean the data\nseawater_clean <- seawater_samples %>% \n  drop_na() %>% \n  rename(temp = t_deg_c, # variables are renamed so they are easier to work with and understand\n         depth = depth_m,\n         phosphate = po4u_m,\n         nitrite = no2u_m)\n\n\nCreate linear regression models using functions to store the equations\nModel 1 is oxygen saturation as a function of water temperature, salinity, and phosphate concentration.\nModel 2 is oxygen saturation as a function of water temperature, salinity, phosphate concentration, and depth.\nA third model has also been added. Model 3 is oxygen saturation as a function of water temperature, salinity, phosphate concentration, nitrite concentration, and depth.\nf1 <- o2sat ~ temp + salinity + phosphate\nmdl1 <- lm(f1, data = seawater_clean)\n\nf2 <- o2sat ~ temp + salinity + phosphate + depth\nmdl2 <- lm(f2, data = seawater_clean)\n\nf3 <- o2sat ~ temp + salinity + phosphate + + nitrite + depth\nmdl3 <- lm(f3, data = seawater_clean)\n\n\nUse AIC to compare the models\nAIC = Akaike Information Criterion\nModel with the lowest AIC is the preferred model. Ideally, the best model is lower than the next best model by at least 2.0. A difference of 2 indicates a significant difference in model fit.\nAICc(mdl1) # AICc() corrects for sample size\n## [1] 619.0251\nAICc(mdl2)\n## [1] 616.6048\nAICc(mdl3)\n## [1] 613.5962\nAICcmodavg::aictab(list(mdl1, mdl2, mdl3))\n## \n## Model selection based on AICc:\n## \n##      K   AICc Delta_AICc AICcWt Cum.Wt      LL\n## Mod3 7 613.60       0.00   0.78   0.78 -299.19\n## Mod2 6 616.60       3.01   0.17   0.95 -301.85\n## Mod1 5 619.03       5.43   0.05   1.00 -304.19\nAIC of model 1 = 619.0251\nAIC of model 2 = 616.6048\nAIC of model 3 = 613.5962\nThe AIC of model 1 > model 2 > model 3.\nModel 3 is lower than model 2 by 3.01 and lower than model 1 by 5.43, so since it is lower by at least 2, model 3 is the preferred model.\nModel 3 is the preferred model via the AIC method.\n\n\nUse 10-fold cross validation to compare the models\nRoot-mean-square error is the scoring method.\nfolds <- 10 # number of folds\nfold_vec <- rep(1:folds, length.out = nrow(seawater_clean)) # fold vector is repeating over each fold\ntable(fold_vec)\n## fold_vec\n##  1  2  3  4  5  6  7  8  9 10 \n## 10 10 10 10 10 10 10 10 10 10\nset.seed(42) # allows others to get same set of random numbers if they try to replicate this work\n\nseawater_fold <- seawater_clean %>% \n  mutate(group = sample(fold_vec, size = n(), replace = FALSE))\nCreate root-mean-square error function.\ncalc_rmse <- function(x, y) {\n  rmse_result <- (x-y)^2 %>% mean() %>% sqrt()\n  return(rmse_result)\n}\nCalculate over all folds and take the average.\nrmse_df <- data.frame() # Create a blank data frame.\n\n# Below is a for loop - loops through all 10 folds.\nfor(i in 1:folds) {\n  kfold_test_df <-seawater_fold %>% \n    filter(group == i) # in group i\n  kfold_train_df <-seawater_fold %>% \n    filter(group != i) # not in group i\n  \n  kfold_mdl1 <- lm(f1, data = kfold_train_df)\n  kfold_mdl2 <- lm(f2, data = kfold_train_df)\n  kfold_mdl3 <- lm(f3, data = kfold_train_df)\n  \n  kfold_pred_df <- kfold_test_df %>% \n    mutate(mdl1 = predict(kfold_mdl1, kfold_test_df),\n           mdl2 = predict(kfold_mdl2, .), # the period is a shortcut that says you are predicting on the data frame\n           mdl3 = predict(kfold_mdl3, .)) \n  kfold_rmse <- kfold_pred_df %>% \n    summarize(rmse_mdl1 = calc_rmse(mdl1, o2sat),\n              rmse_mdl2 = calc_rmse(mdl2, o2sat),\n              rmse_mdl3 = calc_rmse(mdl3, o2sat))\n  \n  #Store the last chunk above by combining with the blank data frame from above.\n  rmse_df <- bind_rows(rmse_df, kfold_rmse)\n}\n\nrmse_df %>% \n  summarize(mean_rmse_mdl1 = mean(rmse_mdl1),\n            mean_rmse_mdl2 = mean(rmse_mdl2),\n            mean_rmse_mdl3 = mean(rmse_mdl3))\n##   mean_rmse_mdl1 mean_rmse_mdl2 mean_rmse_mdl3\n## 1       4.976605       4.876322       4.795063\nModel 1 RMSE = 4.976605\nModel 2 RMSE = 4.876322\nModel 3 RMSE = 4.795063\nModel 3 has the lowest root-mean-square error meaning it has the lowest error when predicting data.\nModel 3 is the preferred model via the k-fold cross validation method using RMSE scoring.\nBoth AIC and k-fold cross validation using root-mean-square error as the scoring method indicate model 3 to be the preferred model.\n\n\nThe coefficients for the final predictive model are identified:\nfinal_mdl <- lm(f3, data = seawater_clean)\nsummary(final_mdl)\n## \n## Call:\n## lm(formula = f3, data = seawater_clean)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -25.3273  -2.3744   0.0158   2.3748  19.4893 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 149.93538   93.39120   1.605   0.1117    \n## temp         -0.46764    0.41548  -1.126   0.2632    \n## salinity     -0.78711    2.92993  -0.269   0.7888    \n## phosphate   -37.37466    2.45287 -15.237   <2e-16 ***\n## nitrite      14.66437    6.46880   2.267   0.0257 *  \n## depth        -0.01789    0.01591  -1.124   0.2637    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.972 on 94 degrees of freedom\n## Multiple R-squared:  0.9597, Adjusted R-squared:  0.9575 \n## F-statistic: 447.1 on 5 and 94 DF,  p-value: < 2.2e-16\n\n\nThe final model:\n\\[\n\\begin{aligned}\n\\operatorname{o2sat} &= \\alpha + \\beta_{1}(\\operatorname{temp}) + \\beta_{2}(\\operatorname{salinity}) + \\beta_{3}(\\operatorname{phosphate})\\ + \\\\\n&\\quad \\beta_{4}(\\operatorname{nitrite}) + \\beta_{5}(\\operatorname{depth}) + \\epsilon\n\\end{aligned}\n\\]\nWhere:\no2sat = oxygen saturation\ntemp = water temperature in degrees Celsius\nsalinity = salinity of the water\nphosphate = phosphate concentration in micro moles per liter\nnitrite = nitrite concentration in micro moles per liter\ndepth = depth in meters\n\n\nThe final model with numbers:\n\\[\n\\begin{aligned}\n\\operatorname{\\widehat{o2sat}} &= 149.94 - 0.47(\\operatorname{temp}) - 0.79(\\operatorname{salinity}) - 37.37(\\operatorname{phosphate})\\ + \\\\\n&\\quad 14.66(\\operatorname{nitrite}) - 0.02(\\operatorname{depth})\n\\end{aligned}\n\\]\n\n\n\n3. Binary Logistic Regression to Identify Palmetto Species\n\nOverview\nThis script uses variables such as plant height, canopy length, canopy width, and the number of green leaves to classify whether palmettos are of species Serenoa repens or Sabal etonia. Binary logistic regression is used to test feasibility.\nData was collected from 1981 to 2017 in south-central Florida. It includes information regarding year, plant type, species, site, habitat, treatment, survival, height, canopy length, canopy width, number of green leaves, scape, new leaves, canopy, if long, comments, and biomass.\nData citation: Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5\nlibrary(tidyverse)\nlibrary(here)\nlibrary(GGally)\nlibrary(broom)\nlibrary(jtools)\nlibrary(caret)\nlibrary(AICcmodavg)\nlibrary(data.table)\nlibrary(knitr)\npalmetto <- read_csv(here(\"data\", \"palmetto.csv\")) # Read in the data\n\n\nWrangle the data\nSelect columns for use in the analysis, change values in the species column to species names, and convert the species column to a factor class.\npalmetto_clean <- palmetto %>% # Clean the data table\n  select(species, height:green_lvs) %>% # Select only the columns I need for analysis, the colon means \"all the way over to\"\n  drop_na()\n\n# Change the values 1 and 2 in the species column to actual species names. 1 = Serenoa repens, 2 = Sabal etonia\npalmetto_clean$species <- ifelse(palmetto_clean$species==1,'Serenoa repens','Sabal etonia') \n\n# Convert the  species column to a factor class\npalmetto_clean$species <- as.factor(palmetto_clean$species) \n\n# levels(palmetto_clean$species) in the console revealed Sabal etonia is factor level 0 and Serenoa repens is factor level 1\n\n\nVisualize the data to identify trends.\nDifferences in height, canopy length, canopy width, and green leaves for Serenoa repens or Sabal etonia.\nggplot(data = palmetto_clean, aes(x = height, y = length)) +\n  geom_point(aes(color = species)) + \n  labs(title = 'Distribution of Height vs. Canopy Length of Two Palmetto Species', \n       x = 'Plant Height (cm)', \n       y = 'Canopy Length (cm)', \n       color = \"Species\") + # title, axis labels, and legend title\n  theme_minimal() # sets the theme of the graph - for visual purposes\n\nFigure 1. The relationship between canopy length (cm) and maximum plant height (cm) is shown for each species. Sabal etonia is shown in red. Serenoa repens is shown in blue.\nggplot(data = palmetto_clean, aes(x = width, y = green_lvs)) +\n  geom_point(aes(color = species)) + \n  labs(title = 'Distribution of Canopy Width vs. Number of Green Leaves of Two Palmetto Species', \nx = 'Canopy Width (cm)', \ny = 'Number of Green Leaves', \ncolor = \"Species\") + # title, axis labels, and legend title\n  theme_minimal() # sets the theme of the graph - for visual purposes\n\nFigure 2. The relationship between the number of green leaves and canopy width (cm) is shown for each species. Sabal etonia is shown in red. Serenoa repens is shown in blue.\nBased on these plots, the number of green leaves is the most likely variable to help classify the species correctly. It shows the most difference between species. Canopy width, plant height, and canopy length showed similar trends between species.\n\n\nBinary logistic regression\n# Store formulas\nf1 <- species ~ height + length + width + green_lvs\n\nf2 <- species ~ height + width + green_lvs\n# Binomial logistic regression for model 1 which includes height + length + width + green_lvs.\npalm_blr1 <- glm(formula = f1, \n                    data = palmetto_clean,\n                    family = 'binomial')\n# Binomial logistic regression for model 2 which includes height + width + green_lvs and does not include length.\npalm_blr2 <- glm(formula = f2, \n                    data = palmetto_clean,\n                    family = 'binomial')\n\n\nIdentify which model performs better\nCompare the models using AICc\nAICcmodavg::aictab(list(palm_blr1, palm_blr2)) # this function compares competing models\n## \n## Model selection based on AICc:\n## \n##      K    AICc Delta_AICc AICcWt Cum.Wt       LL\n## Mod1 5 5194.57       0.00      1      1 -2592.28\n## Mod2 4 5987.48     792.91      0      1 -2989.74\nModel 1 is better because the AIC for model 1 (5194.57) is more than two less than the AIC of model 2 (5987.48).\nCompare with a 10-fold cross-validation, using prediction accuracy as our metric.\n# Using `caret` (\"**C**lassification **A**nd **RE**gression **T**raining\"):\nset.seed(123) \n\n# tr_ctrl <- trainControl(method = \"cv\", number = 10)\ntr_ctrl <- trainControl(method = \"repeatedcv\", number = 10, repeats = 10)\n\n# Train the model\nmodel1 <- train(f1, data = palmetto_clean, \n               method = \"glm\", family = 'binomial',\n               trControl = tr_ctrl)\n\nmodel2 <- train(f2, data = palmetto_clean, \n               method = \"glm\", family = 'binomial',\n               trControl = tr_ctrl)\nModel 1 (92% accurate) is more accurate than model 2 (90% accurate) according to 10-fold cross validation.\nBased on both AIC values and 10-fold cross validation, model 1 is the better model.\n\n\nTrain model 1 using the entire dataset, and create a finalized table containing the binary logistic regression model results\nfinal_mdl <- glm(formula = f1, \n                 data = palmetto_clean, \n                 family = 'binomial')\nTable 1. Model 1 binary logistic regression model results.\n### Get a tidy version w/ broom:\nfinal_mdl_tidy <- broom::tidy(final_mdl)\n\nsetnames(final_mdl_tidy, old=c(\"term\",\"estimate\", \"std.error\", \"statistic\", \"p.value\"), new=c(\"Term\",\"Estimate\", \"Standard Error\", \"z-value\", \"p-value\"))\n\nkable(final_mdl_tidy)\nTerm\nEstimate\nStandard Error\nz-value\np-value\n(Intercept)\n-3.2266851\n0.1420708\n-22.71180\n0\nheight\n0.0292173\n0.0023061\n12.66984\n0\nlength\n-0.0458233\n0.0018661\n-24.55600\n0\nwidth\n-0.0394434\n0.0021000\n-18.78227\n0\ngreen_lvs\n1.9084747\n0.0388634\n49.10728\n0\nThe model is predicting the likelihood that the species is a Serenoa repens because the factor level of Serenoa repens is 1.\nAll variables are statistically significant.\nHigher length and width would be less likely to be Serenoa repens because the value is negative.\nHigher height and more green leaves would be more likely to be a Serenoa repens because the value is positive. This makes sense when looking at graphs above.\n\n\nEvaluation of how successfully this model would “classify” a plant as the correct species, using a 50% cutoff.\nTable 2. Evaluation of how successfully this model would “classify” a plant as the correct species, using a 50% cutoff.\nblr1_fitted <- palm_blr1 %>% # fitted column reports the probability that an individual is a Serenoa repens\n  broom::augment(type.predict = \"response\") %>% # instead of taking the log odds we are taking the odds and converting them into a probability\n  mutate(predicted_species = ifelse(.fitted >= 0.5, \"Serenoa repens\", \"Sabal etonia\")) %>% \n  group_by(species) %>% # separate by species\n  summarize(number_correctly_identified = sum(species == predicted_species),\n            number_total = n()) %>% # number_total is needed to identify percent correctly identified\n  mutate(percent_correctly_identified = number_correctly_identified/number_total * 100) %>% \n  select(species, number_correctly_identified, percent_correctly_identified)\n\nsetnames(blr1_fitted, old=c(\"species\",\"number_correctly_identified\", \"percent_correctly_identified\"), new=c(\"Species\",\"Number Correctly Identified\", \"Percent Correctly Identified\"))\nkable(blr1_fitted)\nSpecies\nNumber Correctly Identified\nPercent Correctly Identified\nSabal etonia\n5701\n92.62388\nSerenoa repens\n5548\n90.77225\nA binary logistic regression model using plant height, canopy length, canopy width and green leaves as predictor variables is better at predicting palmetto species (Serenoa repens and Sabal etonia) than a model using plant height, canopy width and the number of green leaves. The model correctly identified 5701 (92.62%) of Sabal etonia correctly and 5548 (90.77%) of Serenoa repens correctly.\n\n\n\n4. Text Analysis of 2021 IPCC Summary for Policymakers Report\n\nOverview\nThis script uses R to conduct a text analysis of the 2021 Intergovernmental Panel on Climate Change (IPCC) Summary for Policymakers report.\nFirst, data is wrangled to get tokens into tidy format and remove stop words, next counts for the most frequently used words in the text are visualized, then a sentiment analysis using the NRC lexicon is performed.\nData citation: IPCC, 2021: Summary for Policymakers. In: Climate Change 2021: The Physical Science Basis. Contribution of Working Group I to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change [Masson- Delmotte, V., P. Zhai, A. Pirani, S.L. Connors, C. Péan, S. Berger, N. Caud, Y. Chen, L. Goldfarb, M.I. Gomis, M. Huang, K. Leitzell, E. Lonnoy, J.B.R. Matthews, T.K. Maycock, T. Waterfield, O. Yelekçi, R. Yu, and B. Zhou (eds.)]. Cambridge University Press. In Press. https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_SPM_final.pdf\n\n\nLoad necessary packages\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(textdata)\nlibrary(pdftools)\nlibrary(ggwordcloud)\nlibrary(here)\n\n\nLoad the 2021 IPCC Report\nipcc_text <- pdf_text(here('data', 'IPCC_2021pdf.pdf'))\n\n\nGet the IPCC report into a dataframe and remove stop words\nipcc_lines <- data.frame(ipcc_text) %>% \n  mutate(page = 1:n()) %>%\n  mutate(text_full = str_split(ipcc_text, pattern = '\\\\n')) %>% \n  unnest(text_full) %>% \n  mutate(text_full = str_trim(text_full)) \n\n\nipcc_words <- ipcc_lines %>% \n  unnest_tokens(word, text_full) %>% \n  select(-ipcc_text)\n\n# Remove stop words\nhead(stop_words)\n## # A tibble: 6 × 2\n##   word      lexicon\n##   <chr>     <chr>  \n## 1 a         SMART  \n## 2 a's       SMART  \n## 3 able      SMART  \n## 4 about     SMART  \n## 5 above     SMART  \n## 6 according SMART\nipcc_words_clean <- ipcc_words %>% \n  anti_join(stop_words, by = 'word')\n# Count\nnonstop_ipcc_counts <- ipcc_words_clean %>% \n  count(page, word)\n\n\nFind the top 15 words from the document\ntop15 <- nonstop_ipcc_counts %>% \n  arrange(-n) %>% \n  slice(1:15)\n\n\ncloud <- ggplot(data = top15, \n                     aes(label = word)) +\n  geom_text_wordcloud(aes(color = n, size = n), shape = \"diamond\") +\n  scale_size_area(max_size = 6) +\n  scale_color_gradientn(colors = c(\"darkgreen\",\"blue\",\"purple\")) +\n  theme_minimal()\n \ncloud\n\nFigure 1. Wordcloud of the 15 most frequently used words in the 2021 IPCC report.\n\n\nSentiment analysis with NRC lexicon\nNRC lexicon:https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm\nIncludes 8 emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust).\nipcc_nrc <- ipcc_words_clean %>% \n  inner_join(get_sentiments(\"nrc\"))\n# Find the count of words by page and sentiment bin: \nipcc_nrc_counts <- ipcc_nrc %>% \n  count(page, sentiment)\n\nggplot(data = ipcc_nrc_counts, aes(x = sentiment, y = n)) +\n  geom_col() +\n  theme_minimal() +\n  coord_flip() + \n  ggtitle(\"Sentiment Analysis of 2021 IPCC Report\\nusing NRC Lexicon\") +\n  labs(x = \"Sentiment\",\n       y = \"Count\")\n\nFigure 2. Graph of the results of a sentiment analysis, using the NRC lexicon, for the 2021 IPCC report.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// add bootstrap table styles to pandoc tables\nfunction bootstrapStylePandocTables() {\n  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');\n}\n$(document).ready(function () {\n  bootstrapStylePandocTables();\n});\n\n\n\n$(document).ready(function () {\n  window.buildTabsets(\"TOC\");\n});\n\n$(document).ready(function () {\n  $('.tabset-dropdown > .nav-tabs > li').click(function () {\n    $(this).parent().toggleClass('nav-tabs-open');\n  });\n});\n\n$(document).ready(function () {\n  window.initializeCodeFolding(\"hide\" === \"show\");\n});\n\n  (function () {\n    var script = document.createElement(\"script\");\n    script.type = \"text/javascript\";\n    script.src  = \"https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\";\n    document.getElementsByTagName(\"head\")[0].appendChild(script);\n  })();\n",
      "last_modified": "2022-03-07T01:16:34-08:00"
    },
    {
      "path": "Resume.html",
      "title": "Resume",
      "description": "Interests, Education, Experience, and More",
      "author": [],
      "contents": "\nClick here for a PDF\nInterests\nI am keenly interested in working with private landowners to restore and conserve their land and, ultimately, envision myself working for a land trust.\nIn my free time, you will find me hiking, cooking, painting, visiting national parks, and spending as much time with my dog, Basil, as possible.\nEducation\nUniversity of California, Santa Barbara | Santa Barbara, CA\nMaster of Environmental Science and Management | September 2020 - June 2022\nSouthern Illinois University, Carbondale | Carbondale, IL\nB.S. in Zoology & B.S. in Geography and Environmental Resources | August 2016 - May 2020\nMASTER’S GROUP PROJECT\nThe California Solar-Conservation Nexus (4/21 – Present)\nClient: The Nature Conservancy (TNC) | Role: Financial Manager | Deliverables: Report and Presentation\nCollaborate and communicate with team members to conduct spatial analyses, write reports, etc.\nFacilitate meetings with the client and advisors\nDesign an economic model to compare profitability of conservation easements to solar developments\nProvide policy recommendations for conservation and solar development on retired agricultural lands\nENVIRONMENTAL EXPERIENCE\nConservation Connect Fellow – National Forest Foundation (NFF), Boise, ID (5/21– Present)\nCommunicated with stakeholders and U.S. Forest Service (USFS)\nIdentified USFS challenges and wrote a summary report for NFF and the USFS Washington D.C. office\nCreated a business plan for the Southern Idaho Forest Fund for presentation to potential donors\nDesigned a mailer delivered to over 23,000 residents of the Wood River Valley\nFloodplain Restoration GLOBE Intern – The Nature Conservancy (TNC), Havana, IL (6/19–8/19)\nCoordinated with U.S. Fish and Wildlife Service, the Illinois Natural History Survey, and the Illinois River Biological Station performing research and stewardship.\nConducted public use survey and wrote final summary report to guide management strategies.\nCreated 10 stewardship data maps using ArcGIS Desktop to guide future stewardship activities.\nComposed final presentation summating accomplishments and presented to the Illinois Chapter of TNC.\nEnvironmental Resources Intern – Cypress Creek National Wildlife Refuge, Ullin, IL (8/19–12/19)\nCompiled LiDAR DEM rasters of Cypress Creek National Wildlife Refuge using SAGA GIS and ArcGIS Desktop to determine potential restoration areas within 8 habitat types found on the Refuge.\nGuided canoe tours for visitors of the Refuge.\nDirected children’s activities teaching the importance of the local refuge at a Cache River Days event.\nPerformed radio telemetry to locate endangered Indiana bat roosts to better understand their habits.\nCOMMUNICATION & RESEARCH EXPERIENCE\nResearch Assistant – Southern Illinois University, Dr. Jason Brown Lab, Carbondale, IL (8/19–5/20)\nCollaborated in creation of Tangible Niche & Demographic Simulator (TANAGERS) which combines environmental and biological variables to create a powerful population genetics teaching tool.\nEmployed GRASS GIS in construction of TANAGERS.\nPresented TANAGERS at Southern Illinois University Annual Research Presentation (50+ audience).\nCooperated with a computer science student to streamline the simulator function.\nStudent Researcher – Southern Illinois University, Carbondale, IL (8/18–5/19)\nDesigned, wrote, and awarded a grant proposal ($2000) for research on the Effects of Strip Mine Reclamation Practices on Terrestrial Snail Communities.\nConducted independent research and led a team of student assistants.\nAmplified a region of mitochondrial rrnL (16s) gene via PCR to aid snail identification.\nPresented poster in-person to 300 attendees at the World Congress of Malacology.\nResearch Assistant – University of Illinois, Illinois Natural History Survey, Sullivan, IL (6/18–8/18)\nSampled mid-sized rivers via electrofishing, side scan sonar, and other methods.\nAnalyzed data using ArcGIS Desktop to identify habitat-fish associations.\nWrote a protocol to guide future employees.\nCollaborated with researchers from Eastern Illinois University.\nResearch Intern – National Great Rivers Research and Education Center, East Alton, IL (6/17–8/17)\nCoordinated sampling of mid-sized river habitat (Kaskaskia and Embarras Rivers in Illinois).\nInterpreted side scan sonar images to identify woody debris using ArcGIS Desktop.\nIdentified fish species (larval, juvenile, and adult).\nComposed final PowerPoint presentation to demonstrate the educational benefit of the internship.\nPROFESSIONAL PRESENTATIONS\nEffects of Strip Mine Reclamation Practices on Terrestrial Snails, World Congress of Malacology, 2019\nStrip Mine Reclamation – Reestablishing Sustainable Ecosystems in Southern Illinois, Department of Geography and Environmental Resources (Southern Illinois University) Annual Poster Session, 2019 Habitat Value in Mid-Sized Rivers in Illinois, Illinois Academy of Science, 2018\nSKILLS\nComputer: ArcGIS (Desktop and Pro), Microsoft Office Suite, Marxan, MaxEnt, SDMtoolbox, Circuitscape, ERDAS Imagine, QGIS, R, GitHub, Zoom, Cisco Webex, Slack, data analysis, social media\nTechnical: GPS, DNA barcoding, side scan sonar, electrofishing, radio telemetry, grant writing Public Outreach: Leading public programs, conducting surveys, youth education programs\nField: Prescribed burn assistance, fish sampling/identification, snail sampling/identification, mammal sampling techniques, bird surveys, plant surveys, invasive plant identification and removal, benthic substrate sampling, soil analyses, boat and vehicle operation\n\n\n\n",
      "last_modified": "2022-03-07T01:16:35-08:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
