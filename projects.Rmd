---
title: "Projects"
description: |
  Projects Completed
output:
  html_document:
    code_folding: hide
---

## 1. Principal Components Analysis to Analyze Food Nutrients

### Overview
This script uses principal components analysis to analyze nutrient information for raw fruits and vegetables from the USDA National Nutrient Database (FoodDataCentral). Principal components analysis is an ordination method allowing us to understand as much about our multivariate data as possible in a simplified number of dimensions. Here, I'll use the `nutrients` data from the USDA to explore variable relationships and clustering. I will only use the measurements that are in grams (protein, fat, carbohydrates, sugar, fiber), and I will only look at restaurant foods, baked products, and beef products.

**Data citation:** United States Department of Agriculture. https://fdc.nal.usda.gov/index.html


### Attach required packages:
```{r setup, include = TRUE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
 
library(tidyverse)
library(here)
library(ggfortify) # For PCA biplot
library(patchwork)
library(broom)
```

### Read in the data
```{r}
nutrients <- read_csv(here("data", "usda_nutrients.csv"))
```

### Filter the data
```{r}
# Filter food groups for restaurant foods, baked products, and beef products.
nutrients_filter <- nutrients %>% 
  filter(FoodGroup == c("Restaurant Foods", "Baked Products", "Beef Products"))
```

### Run the PCA
```{r}
nutrients_pca <- nutrients_filter %>% 
  select(ends_with('_g')) %>% 
  scale() %>% # scale the selected variables and pass to the prcomp() function
  prcomp()
```

### Create a biplot using autoplot
```{r}
autoplot(nutrients_pca,
     	data = nutrients_filter,
     	loadings = TRUE,
     	colour = 'FoodGroup', # colour needs to be British spelling
     	loadings.label = TRUE,
     	loadings.colour = "black",
     	loadings.label.colour = "black",
     	loadings.label.vjust = -0.5) +
  theme_classic()
```

**Figure 1.** PCA biplot between PC1 and PC2 when looking at protein, fiber, carbohydrates, sugar, and fat of baked products, beef products, and restaurant foods. 

### Summary
- All three food groups seem to have distinct clusters.
- Beef products associate more strongly with protein than with the other nutrients. 
- Fiber, carbs, and sugars tend to be more similar to each other than to protein. They are positively correlated.
- Protein is about 180 degrees different than carbs and sugars. This means they have a correlation of -1.
- Fiber and fat have a correlation of 0 since they are about 90 degrees.
- Baked products are more similar to restaurant food than beef products based on these variables.
- Of the three clusters, beef products and baked products are the most different.
 
 
 
 
 
 
## 2. Analysis of Seawater

### Overview
This analysis will look at the relationship between oxygen saturation of seawater off California’s coast and several physical and chemical variables including oxygen saturation, water temperature, water salinity, water depth, phosphate concentration, and nitrite concentrations.

Data citation: CalCOFI data are available for use without restriction. Data downloaded from https://calcofi.org/ccdata.html.  Accessed 1/10/2022.

### Attach required packages
```{r}

# load packages
library(tidyverse)
library(here)
library(AICcmodavg)
library(equatiomatic)
```

### Read in the data
```{r}
seawater_samples <- read_csv(here('data', 'calcofi_seawater_samples.csv'))
```

### Clean the data
```{r}
seawater_clean <- seawater_samples %>% 
  drop_na() %>% 
  rename(temp = t_deg_c, # variables are renamed so they are easier to work with and understand
         depth = depth_m,
         phosphate = po4u_m,
         nitrite = no2u_m)
```

### Create linear regression models using functions to store the equations
Model 1 is oxygen saturation as a function of water temperature, salinity, and phosphate concentration.

Model 2 is oxygen saturation as a function of water temperature, salinity, phosphate concentration, and depth.

A third model has also been added. Model 3 is oxygen saturation as a function of water temperature, salinity, phosphate concentration, nitrite concentration, and depth.

```{r}
f1 <- o2sat ~ temp + salinity + phosphate
mdl1 <- lm(f1, data = seawater_clean)

f2 <- o2sat ~ temp + salinity + phosphate + depth
mdl2 <- lm(f2, data = seawater_clean)

f3 <- o2sat ~ temp + salinity + phosphate + + nitrite + depth
mdl3 <- lm(f3, data = seawater_clean)
```

### Use AIC to compare the models
AIC = Akaike Information Criterion

Model with the lowest AIC is the preferred model. Ideally, the best model is lower than the next best model by at least 2.0. A difference of 2 indicates a significant difference in model fit.

```{r}
AICc(mdl1) # AICc() corrects for sample size

AICc(mdl2)

AICc(mdl3)

AICcmodavg::aictab(list(mdl1, mdl2, mdl3))
```

- AIC of model 1 = 619.0251

- AIC of model 2 = 616.6048

- AIC of model 3 = 613.5962

- The AIC of model 1 > model 2 > model 3.

- Model 3 is lower than model 2 by 3.01 and lower than model 1 by 5.43, so since it is lower by at least 2, model 3 is the preferred model.

- Model 3 is the preferred model via the AIC method.


### Use 10-fold cross validation to compare the models
Root-mean-square error is the scoring method.

```{r}
folds <- 10 # number of folds
fold_vec <- rep(1:folds, length.out = nrow(seawater_clean)) # fold vector is repeating over each fold
table(fold_vec)

set.seed(42) # allows others to get same set of random numbers if they try to replicate this work

seawater_fold <- seawater_clean %>% 
  mutate(group = sample(fold_vec, size = n(), replace = FALSE))
```

Create root-mean-square error function.

```{r}
calc_rmse <- function(x, y) {
  rmse_result <- (x-y)^2 %>% mean() %>% sqrt()
  return(rmse_result)
}
```

Calculate over all folds and take the average.

```{r}
rmse_df <- data.frame() # Create a blank data frame.

# Below is a for loop - loops through all 10 folds.
for(i in 1:folds) {
  kfold_test_df <-seawater_fold %>% 
    filter(group == i) # in group i
  kfold_train_df <-seawater_fold %>% 
    filter(group != i) # not in group i
  
  kfold_mdl1 <- lm(f1, data = kfold_train_df)
  kfold_mdl2 <- lm(f2, data = kfold_train_df)
  kfold_mdl3 <- lm(f3, data = kfold_train_df)
  
  kfold_pred_df <- kfold_test_df %>% 
    mutate(mdl1 = predict(kfold_mdl1, kfold_test_df),
           mdl2 = predict(kfold_mdl2, .), # the period is a shortcut that says you are predicting on the data frame
           mdl3 = predict(kfold_mdl3, .)) 
  kfold_rmse <- kfold_pred_df %>% 
    summarize(rmse_mdl1 = calc_rmse(mdl1, o2sat),
              rmse_mdl2 = calc_rmse(mdl2, o2sat),
              rmse_mdl3 = calc_rmse(mdl3, o2sat))
  
  #Store the last chunk above by combining with the blank data frame from above.
  rmse_df <- bind_rows(rmse_df, kfold_rmse)
}

rmse_df %>% 
  summarize(mean_rmse_mdl1 = mean(rmse_mdl1),
            mean_rmse_mdl2 = mean(rmse_mdl2),
            mean_rmse_mdl3 = mean(rmse_mdl3))

```

- Model 1 RMSE = 4.976605

- Model 2 RMSE = 4.876322

- Model 3 RMSE = 4.795063

- Model 3 has the lowest root-mean-square error meaning it has the lowest error when predicting data.

- Model 3 is the preferred model via the k-fold cross validation method using RMSE scoring.


**Both AIC and k-fold cross validation using root-mean-square error as the scoring method indicate model 3 to be the preferred model.**

### The coefficients for the final predictive model are identified:

```{r}
final_mdl <- lm(f3, data = seawater_clean)
summary(final_mdl)
```

### The final model:
`r equatiomatic::extract_eq(final_mdl, wrap = TRUE)`


Where:

- o2sat = oxygen saturation

- temp = water temperature in degrees Celsius

- salinity = salinity of the water

- phosphate = phosphate concentration in micro moles per liter

- nitrite = nitrite concentration in micro moles per liter

- depth = depth in meters


### The final model with numbers:
`r equatiomatic::extract_eq(final_mdl, wrap = TRUE, use_coefs = TRUE)`
 
 
 
 
 
 
## 3. Binary Logistic Regression to Identify Palmetto Species

### Overview
This script uses variables such as plant height, canopy length, canopy width, and the number of green leaves to classify whether palmettos are of species *Serenoa repens* or *Sabal etonia*. Binary logistic regression is used to test feasibility.

Data was collected from 1981 to 2017 in south-central Florida. It includes information regarding year, plant type, species, site, habitat, treatment, survival, height, canopy length, canopy width, number of green leaves, scape, new leaves, canopy, if long, comments, and biomass.

**Data citation:** Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5


```{r}
library(tidyverse)
library(here)
library(GGally)
library(broom)
library(jtools)
library(caret)
library(AICcmodavg)
library(data.table)
library(knitr)
```

```{r}
palmetto <- read_csv(here("data", "palmetto.csv")) # Read in the data
```

### Wrangle the data
Select columns for use in the analysis, change values in the species column to species names, and convert the species column to a factor class.

```{r}
palmetto_clean <- palmetto %>% # Clean the data table
  select(species, height:green_lvs) %>% # Select only the columns I need for analysis, the colon means "all the way over to"
  drop_na()

# Change the values 1 and 2 in the species column to actual species names. 1 = Serenoa repens, 2 = Sabal etonia
palmetto_clean$species <- ifelse(palmetto_clean$species==1,'Serenoa repens','Sabal etonia') 

# Convert the  species column to a factor class
palmetto_clean$species <- as.factor(palmetto_clean$species) 

# levels(palmetto_clean$species) in the console revealed Sabal etonia is factor level 0 and Serenoa repens is factor level 1
```

### Visualize the data to identify trends.

Differences in height, canopy length, canopy width, and green leaves for *Serenoa repens* or *Sabal etonia*.

```{r, include = FALSE}
palmetto_clean %>% 
  ggpairs(aes(color = species)) # Used to get an overview of data before final visualizations are made
```

```{r}
ggplot(data = palmetto_clean, aes(x = height, y = length)) +
  geom_point(aes(color = species)) + 
  labs(title = 'Distribution of Height vs. Canopy Length of Two Palmetto Species', 
       x = 'Plant Height (cm)', 
       y = 'Canopy Length (cm)', 
       color = "Species") + # title, axis labels, and legend title
  theme_minimal() # sets the theme of the graph - for visual purposes
```

**Figure 1.** The relationship between canopy length (cm) and maximum plant height (cm) is shown for each species. *Sabal etonia* is shown in red. *Serenoa repens* is shown in blue.


```{r}
ggplot(data = palmetto_clean, aes(x = width, y = green_lvs)) +
  geom_point(aes(color = species)) + 
  labs(title = 'Distribution of Canopy Width vs. Number of Green Leaves of Two Palmetto Species', 
x = 'Canopy Width (cm)', 
y = 'Number of Green Leaves', 
color = "Species") + # title, axis labels, and legend title
  theme_minimal() # sets the theme of the graph - for visual purposes
```

**Figure 2.** The relationship between the number of green leaves and canopy width (cm) is shown for each species. *Sabal etonia* is shown in red. *Serenoa repens* is shown in blue. 

Based on these plots, the number of green leaves is the most likely variable to help classify the species correctly. It shows the most difference between species. Canopy width, plant height, and canopy length showed similar trends between species.

### Binary logistic regression

```{r}
# Store formulas
f1 <- species ~ height + length + width + green_lvs

f2 <- species ~ height + width + green_lvs
```


```{r}
# Binomial logistic regression for model 1 which includes height + length + width + green_lvs.
palm_blr1 <- glm(formula = f1, 
                    data = palmetto_clean,
                    family = 'binomial')
```


```{r}
# Binomial logistic regression for model 2 which includes height + width + green_lvs and does not include length.
palm_blr2 <- glm(formula = f2, 
                    data = palmetto_clean,
                    family = 'binomial')
```

### Identify which model performs better
Compare the models using AICc

```{r}
AICcmodavg::aictab(list(palm_blr1, palm_blr2)) # this function compares competing models
```

- Model 1 is better because the AIC for model 1 (5194.57) is more than two less than the AIC of model 2 (5987.48).


Compare with a 10-fold cross-validation, using prediction accuracy as our metric.

```{r}
# Using `caret` ("**C**lassification **A**nd **RE**gression **T**raining"):
set.seed(123) 

# tr_ctrl <- trainControl(method = "cv", number = 10)
tr_ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)

# Train the model
model1 <- train(f1, data = palmetto_clean, 
               method = "glm", family = 'binomial',
               trControl = tr_ctrl)

model2 <- train(f2, data = palmetto_clean, 
               method = "glm", family = 'binomial',
               trControl = tr_ctrl)
```

- Model 1 (92% accurate) is more accurate than model 2 (90% accurate) according to 10-fold cross validation.

- **Based on both AIC values and 10-fold cross validation, model 1 is the better model.**

### Train model 1 using the entire dataset, and create a finalized table containing the binary logistic regression model results 

```{r}
final_mdl <- glm(formula = f1, 
                 data = palmetto_clean, 
                 family = 'binomial')
```


**Table 1.** Model 1 binary logistic regression model results.

```{r}
### Get a tidy version w/ broom:
final_mdl_tidy <- broom::tidy(final_mdl)

setnames(final_mdl_tidy, old=c("term","estimate", "std.error", "statistic", "p.value"), new=c("Term","Estimate", "Standard Error", "z-value", "p-value"))

kable(final_mdl_tidy)
```

- The model is predicting the likelihood that the species is a *Serenoa repens* because the factor level of *Serenoa repens* is 1.

- All variables are statistically significant.

- Higher length and width would be less likely to be *Serenoa repens* because the value is negative.

- Higher height and more green leaves would be more likely to be a *Serenoa repens* because the value is positive. This makes sense when looking at graphs above.

### Evaluation of how successfully this model would “classify” a plant as the correct species, using a 50% cutoff.

**Table 2.** Evaluation of how successfully this model would “classify” a plant as the correct species, using a 50% cutoff.

```{r}
blr1_fitted <- palm_blr1 %>% # fitted column reports the probability that an individual is a Serenoa repens
  broom::augment(type.predict = "response") %>% # instead of taking the log odds we are taking the odds and converting them into a probability
  mutate(predicted_species = ifelse(.fitted >= 0.5, "Serenoa repens", "Sabal etonia")) %>% 
  group_by(species) %>% # separate by species
  summarize(number_correctly_identified = sum(species == predicted_species),
            number_total = n()) %>% # number_total is needed to identify percent correctly identified
  mutate(percent_correctly_identified = number_correctly_identified/number_total * 100) %>% 
  select(species, number_correctly_identified, percent_correctly_identified)

setnames(blr1_fitted, old=c("species","number_correctly_identified", "percent_correctly_identified"), new=c("Species","Number Correctly Identified", "Percent Correctly Identified"))
kable(blr1_fitted)
```

A binary logistic regression model using plant height, canopy length, canopy width and green leaves as predictor variables is better at predicting palmetto species (*Serenoa repens* and *Sabal etonia*) than a model using plant height, canopy width and the number of green leaves. The model correctly identified 5701 (92.62%) of *Sabal etonia* correctly and 5548 (90.77%) of *Serenoa repens* correctly.
 
  
   
    
     
      
## 4. Text Analysis of 2021 IPCC Summary for Policymakers Report

### Overview
This script uses R to conduct a text analysis of the 2021 Intergovernmental Panel on Climate Change (IPCC) Summary for Policymakers report.

First, data is wrangled to get tokens into tidy format and remove stop words, next counts for the most frequently used words in the text are visualized, then a sentiment analysis using the NRC lexicon is performed.

**Data citation:** 
IPCC, 2021: Summary for Policymakers. In: Climate Change 2021: The Physical Science Basis. Contribution of Working Group I to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change [Masson- Delmotte, V., P. Zhai, A. Pirani, S.L. Connors, C. Péan, S. Berger, N. Caud, Y. Chen, L. Goldfarb, M.I. Gomis, M. Huang, K. Leitzell, E. Lonnoy, J.B.R. Matthews, T.K. Maycock, T. Waterfield, O. Yelekçi, R. Yu, and B. Zhou (eds.)]. Cambridge University Press. In Press. https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_SPM_final.pdf

### Load necessary packages
```{r}
library(tidyverse)
library(tidytext)
library(textdata)
library(pdftools)
library(ggwordcloud)
library(here)
```

### Load the 2021 IPCC Report
```{r, cache = TRUE}
ipcc_text <- pdf_text(here('data', 'IPCC_2021pdf.pdf'))
```

### Get the IPCC report into a dataframe and remove stop words
```{r}
ipcc_lines <- data.frame(ipcc_text) %>% 
  mutate(page = 1:n()) %>%
  mutate(text_full = str_split(ipcc_text, pattern = '\\n')) %>% 
  unnest(text_full) %>% 
  mutate(text_full = str_trim(text_full)) 


ipcc_words <- ipcc_lines %>% 
  unnest_tokens(word, text_full) %>% 
  select(-ipcc_text)

# Remove stop words
head(stop_words)
 
ipcc_words_clean <- ipcc_words %>% 
  anti_join(stop_words, by = 'word')
```

```{r}
# Count
nonstop_ipcc_counts <- ipcc_words_clean %>% 
  count(page, word)
```

### Find the top 15 words from the document
```{r}
top15 <- nonstop_ipcc_counts %>% 
  arrange(-n) %>% 
  slice(1:15)


cloud <- ggplot(data = top15, 
                     aes(label = word)) +
  geom_text_wordcloud(aes(color = n, size = n), shape = "diamond") +
  scale_size_area(max_size = 6) +
  scale_color_gradientn(colors = c("darkgreen","blue","purple")) +
  theme_minimal()
 
cloud
```

**Figure 1.** Wordcloud of the 15 most frequently used words in the 2021 IPCC report.

### Sentiment analysis with NRC lexicon

NRC lexicon:https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm

Includes 8 emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust).

```{r}
ipcc_nrc <- ipcc_words_clean %>% 
  inner_join(get_sentiments("nrc"))
```

```{r}
# Find the count of words by page and sentiment bin: 
ipcc_nrc_counts <- ipcc_nrc %>% 
  count(page, sentiment)

ggplot(data = ipcc_nrc_counts, aes(x = sentiment, y = n)) +
  geom_col() +
  theme_minimal() +
  coord_flip() + 
  ggtitle("Sentiment Analysis of 2021 IPCC Report\nusing NRC Lexicon") +
  labs(x = "Sentiment",
       y = "Count")
```

**Figure 2.** Graph of the results of a sentiment analysis, using the 
NRC lexicon, for the 2021 IPCC report.